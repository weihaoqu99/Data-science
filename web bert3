#!/usr/bin/env python
import os
import sys
import argparse
from pathlib import Path

import pandas as pd
import torch
import torch.nn.functional as F
import evaluate   # <-- HF-Evaluate

from transformers import RobertaTokenizer, RobertaModel

# ─── CONFIG ────────────────────────────────────────────────────────────────

# adjust these if you move things around:
SCRIPT_PATH   = Path(__file__).resolve()                  # .../Automation_Scripts/bertscore.py
SCRIPT_DIR    = SCRIPT_PATH.parent                         # .../Automation_Scripts
MODEL_DIR     = Path(
    os.getenv("BERT", 
              r"C:/Users/ZKC7HOU/Documents/4. BERT score/roberta-large")
)
BASELINE_PATH = Path(
    os.getenv("BASELINE",
              r"C:/Users/ZKC7HOU/Documents/4. BERT score/roberta-large/roberta-large.tsv")
)
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ─── LOAD CUSTOM METRIC ───────────────────────────────────────────────────

try:
    # point directly at this file, not the folder
    scorer = evaluate.load(
        path=str(SCRIPT_PATH),
        module_type="metric"
    )
    print("✅ Loaded local bertscore metric")
except Exception as e:
    print(f"❌ ERROR: failed to load bertscore metric: {e}", file=sys.stderr)
    scorer = None

# ─── CLI ENTRYPOINT ────────────────────────────────────────────────────────

def cli_main(input_files: list[str], output_dir: Path):
    if scorer is None:
        print("❌ ERROR: scorer not loaded, aborting", file=sys.stderr)
        sys.exit(1)

    # 1) read & concat
    dfs = []
    for fn in input_files:
        p = Path(fn)
        suf = p.suffix.lower()
        if suf in (".xls", ".xlsx"):
            dfs.append(pd.read_excel(p))
        elif suf == ".csv":
            dfs.append(pd.read_csv(p))
        else:
            print(f"❌ ERROR: unsupported file type {suf}", file=sys.stderr)
            sys.exit(1)

    if not dfs:
        print("❌ ERROR: no data loaded", file=sys.stderr)
        sys.exit(1)
    df = pd.concat(dfs, ignore_index=True)

    # 2) sanity check
    for col in ("reference", "candidate"):
        if col not in df.columns:
            print(f"❌ ERROR: missing required column '{col}'", file=sys.stderr)
            sys.exit(1)

    # 3) compute in one shot
    out = scorer.compute(
        predictions=[c.strip() for c in df["candidate"].astype(str)],
        references=[r.strip() for r in df["reference"].astype(str)],
        model_type=str(MODEL_DIR),
        num_layers=17,
        device=DEVICE,
        rescale_with_baseline=True,
        baseline_path=str(BASELINE_PATH),
        lang="en"
    )

    # 4) attach & write Excel
    df["precision"] = out["precision"]
    df["recall"]    = out["recall"]
    df["f1"]        = out["f1"]

    output_dir.mkdir(parents=True, exist_ok=True)
    out_fp = output_dir / "Bertscore_output.xlsx"
    with pd.ExcelWriter(out_fp, engine="xlsxwriter") as writer:
        # a) per‐sentence
        df[["reference","candidate","precision","recall","f1"]] \
          .to_excel(writer, sheet_name="Detailed metrics", index=False)
        # b) macro averages
        summary = pd.DataFrame([{
            "precision": df["precision"].mean(),
            "recall":    df["recall"].mean(),
            "f1":        df["f1"].mean()
        }]).round(6)
        summary.to_excel(writer, sheet_name="Model metrics", index=False)

    print(f"✔️ Report saved to: {out_fp.resolve()}")

# ─── ARGPARSE BOILERPLATE ──────────────────────────────────────────────────

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Offline BERTScore CLI (local RoBERTa-large + baseline rescaling)"
    )
    parser.add_argument(
        "--output_dir",
        type=Path,
        required=True,
        help="Directory to write Bertscore_output.xlsx"
    )
    parser.add_argument(
        "files",
        nargs="+",
        help="One or more .csv/.xls/.xlsx files with 'reference' & 'candidate' columns"
    )
    args = parser.parse_args()
    cli_main(args.files, args.output_dir)
    