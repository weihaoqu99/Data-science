#!/usr/bin/env python
import os
import sys
import argparse
import traceback
from pathlib import Path

import pandas as pd
import torch
import torch.nn.functional as F
from transformers import RobertaTokenizer, RobertaModel
import evaluate  # loads this file as a local metric module

# ─── Configuration ─────────────────────────────────────────────────────────
# SCRIPT_DIR is the directory containing this script (Automation_Scripts)
SCRIPT_DIR    = Path(__file__).parent
# Use forward‐slashes in your path string; Path will normalize on Windows
MODEL_DIR     = Path("C:/Users/ZKC7HOU/Documents/4. BERT score/roberta-large")
BASELINE_PATH = MODEL_DIR / "roberta-large.tsv"
DEVICE        = "cuda" if torch.cuda.is_available() else "cpu"


# ─── 1) load your local bertscore metric (this file itself) ────────────────
try:
    scorer = evaluate.load(
        path=str(SCRIPT_DIR.resolve()),
        module_type="metric"
    )
    print("✅ Loaded local bertscore metric")
except Exception as e:
    print("❌ ERROR: failed to load bertscore metric:", e, file=sys.stderr)
    sys.exit(1)


# ─── 2) load the offline RoBERTa tokenizer + model ─────────────────────────
if not MODEL_DIR.is_dir():
    print(f"❌ ERROR: cannot find model folder at {MODEL_DIR}", file=sys.stderr)
    sys.exit(1)

try:
    tokenizer = RobertaTokenizer.from_pretrained(
        str(MODEL_DIR),
        local_files_only=True,
        use_fast=False
    )
    model = (
        RobertaModel
        .from_pretrained(str(MODEL_DIR), local_files_only=True)
        .to(DEVICE)
        .eval()
    )
    print("✅ Loaded local RoBERTa‐large model/tokenizer")
except Exception as e:
    print("❌ ERROR: loading local RoBERTa‐large model/tokenizer failed:", e, file=sys.stderr)
    sys.exit(1)


def cli_main(input_files: list[str], output_dir: Path):
    # ─── Read & concatenate all inputs ──────────────────────────────────────
    dfs = []
    for fn in input_files:
        p = Path(fn)
        suf = p.suffix.lower()
        if suf in (".xls", ".xlsx"):
            try:
                dfs.append(pd.read_excel(p))
            except Exception as e:
                print(f"❌ ERROR reading {p}: {e}", file=sys.stderr)
                sys.exit(1)
        elif suf == ".csv":
            try:
                dfs.append(pd.read_csv(p))
            except Exception as e:
                print(f"❌ ERROR reading {p}: {e}", file=sys.stderr)
                sys.exit(1)
        else:
            print(f"❌ ERROR: unsupported file type {suf}", file=sys.stderr)
            sys.exit(1)

    if not dfs:
        print("❌ ERROR: no data loaded", file=sys.stderr)
        sys.exit(1)

    df = pd.concat(dfs, ignore_index=True)

    # ─── Verify required columns ────────────────────────────────────────────
    for col in ("reference", "candidate"):
        if col not in df.columns:
            print(f"❌ ERROR: missing required column '{col}'", file=sys.stderr)
            sys.exit(1)

    # ─── Compute BERTScore via local metric ─────────────────────────────────
    out = scorer.compute(
        predictions=[c.strip() for c in df["candidate"].astype(str)],
        references=[r.strip() for r in df["reference"].astype(str)],
        model_type=str(MODEL_DIR),
        num_layers=17,
        device=DEVICE,
        rescale_with_baseline=True,
        baseline_path=str(BASELINE_PATH),
        lang="en"
    )

    df["precision"] = out["precision"]
    df["recall"]    = out["recall"]
    df["f1"]        = out["f1"]

    # ─── Write Excel with two sheets ────────────────────────────────────────
    output_dir.mkdir(parents=True, exist_ok=True)
    out_fp = output_dir / "Bertscore_output.xlsx"

    with pd.ExcelWriter(out_fp, engine="xlsxwriter") as writer:
        # 1) detailed per-sentence
        df[["reference", "candidate", "precision", "recall", "f1"]] \
          .to_excel(writer, sheet_name="Detailed metrics", index=False)

        # 2) one-row averages
        summary = pd.DataFrame([{
            "precision": df["precision"].mean(),
            "recall":    df["recall"].mean(),
            "f1":        df["f1"].mean()
        }]).round(6)
        summary.to_excel(writer, sheet_name="Model metrics", index=False)

    print(f"✔️  Report saved to: {out_fp.resolve()}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Offline BERTScore CLI (local RoBERTa-large w/ baseline rescoring)"
    )
    parser.add_argument(
        "--output_dir",
        type=Path,
        required=True,
        help="Directory in which to write Bertscore_output.xlsx"
    )
    parser.add_argument(
        "files",
        nargs="+",
        help="One or more .csv/.xls/.xlsx files with 'reference' & 'candidate' columns"
    )
    args = parser.parse_args()

    cli_main(args.files, args.output_dir)