#!/usr/bin/env python
import os
import sys
import argparse
from pathlib import Path

import pandas as pd
import evaluate

# ─── Configuration ─────────────────────────────────────────────────────────

# This script lives in metrics_webapp/Automation_Scripts/
SCRIPT_DIR        = Path(__file__).parent
MODEL_DIR         = Path(
    os.getenv(
        "BERT",
        r"C:/Users/ZKC7HOU/Documents/4. BERT score/roberta-large"
    )
)
BASELINE_PATH     = Path(
    os.getenv(
        "BASELINE",
        MODEL_DIR / "roberta-large.tsv"
    )
)
DEVICE            = "cuda" if os.getenv("CUDA_VISIBLE_DEVICES") else "cpu"

# ─── Load your local bertscore metric ──────────────────────────────────────
try:
    scorer = evaluate.load(
        path=str(SCRIPT_DIR),    # points at Automation_Scripts/bertscore.py
        module_type="metric"
    )
    print("✅ Loaded local bertscore metric")
except Exception as e:
    print("❌ ERROR: failed to load bertscore metric:", e, file=sys.stderr)
    scorer = None

# ─── Main CLI function ─────────────────────────────────────────────────────
def cli_main(input_files: list[str], output_dir: Path):
    if scorer is None:
        print("❌ ERROR: scorer not loaded, aborting", file=sys.stderr)
        sys.exit(1)

    # 1) read & concat
    dfs = []
    for fn in input_files:
        p = Path(fn)
        suf = p.suffix.lower()
        if suf in (".xls", ".xlsx"):
            dfs.append(pd.read_excel(p))
        elif suf == ".csv":
            dfs.append(pd.read_csv(p))
        else:
            print(f"❌ ERROR: unsupported file type {suf}", file=sys.stderr)
            sys.exit(1)
    if not dfs:
        print("❌ ERROR: no data loaded", file=sys.stderr)
        sys.exit(1)
    df = pd.concat(dfs, ignore_index=True)

    # 2) sanity‐check columns
    for col in ("reference", "candidate"):
        if col not in df.columns:
            print(f"❌ ERROR: missing required column '{col}'", file=sys.stderr)
            sys.exit(1)

    # 3) compute BERTScore in one shot
    out = scorer.compute(
        predictions=[c.strip() for c in df["candidate"].astype(str)],
        references=[r.strip() for r in df["reference"].astype(str)],
        model_type=str(MODEL_DIR),
        num_layers=17,
        device=DEVICE,
        rescale_with_baseline=True,
        baseline_path=str(BASELINE_PATH),
        lang="en"
    )

    df["precision"] = out["precision"]
    df["recall"]    = out["recall"]
    df["f1"]        = out["f1"]

    # 4) write Excel with two sheets
    output_dir.mkdir(parents=True, exist_ok=True)
    out_fp = output_dir / "Bertscore_output.xlsx"
    with pd.ExcelWriter(out_fp, engine="xlsxwriter") as writer:
        # a) per‐sentence details
        df[["reference","candidate","precision","recall","f1"]] \
          .to_excel(writer, sheet_name="Detailed metrics", index=False)
        # b) single‐row macro averages
        summary = pd.DataFrame([{
            "precision": df["precision"].mean(),
            "recall":    df["recall"].mean(),
            "f1":        df["f1"].mean()
        }]).round(6)
        summary.to_excel(writer, sheet_name="Model metrics", index=False)

    print(f"✔️  Report saved to: {out_fp.resolve()}")

# ─── Entry point ───────────────────────────────────────────────────────────
if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Offline BERTScore CLI (local RoBERTa-large w/ baseline rescaling)"
    )
    parser.add_argument(
        "--output_dir",
        type=Path,
        required=True,
        help="Directory to write Bertscore_output.xlsx"
    )
    parser.add_argument(
        "files",
        nargs="+",
        help="One or more .csv/.xls/.xlsx files with 'reference' & 'candidate' columns"
    )
    args = parser.parse_args()
    cli_main(args.files, args.output_dir)
    
    