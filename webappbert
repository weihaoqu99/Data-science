#!/usr/bin/env python3
import os
import sys
import argparse
from pathlib import Path
import warnings

import pandas as pd
import evaluate
import torch

def main(input_files, output_dir):
    # 1) sanity checks
    if not input_files:
        print("‚ùå Error: no input files provided. Pass at least one .xlsx/.xls file.")
        sys.exit(1)
    os.makedirs(output_dir, exist_ok=True)

    # 2) load the BERTScore metric
    warnings.simplefilter("ignore")
    scorer = evaluate.load("bertscore")  # will pick up your local bertscore.py if you overrode
    print("‚úÖ Loaded local BERTScore metric")

    # 3) for each input file, compute scores and write a combined Excel
    for fp in input_files:
        fp = Path(fp)
        print(f"üîÑ Processing {fp}‚Ä¶")
        # read in
        try:
            df = pd.read_excel(fp)
        except Exception as e:
            print(f"‚ùå Could not read Excel {fp}: {e}")
            sys.exit(1)

        # require columns
        for col in ("reference", "candidate"):
            if col not in df.columns:
                print(f"‚ùå Excel {fp} must have a '{col}' column")
                sys.exit(1)

        # prepare lists
        refs  = df["reference"].astype(str).str.strip().tolist()
        cands = df["candidate"].astype(str).str.strip().tolist()

        # compute
        try:
            out = scorer.compute(
                predictions=cands,
                references=refs,
                model_type="roberta-large",                       # ‚Üê important
                num_layers=17,
                device="cuda" if torch.cuda.is_available() else "cpu",
                rescale_with_baseline=True,
                baseline_path=str(Path(__file__).parent / "roberta-large.tsv"),
                lang="en",
            )
        except Exception as e:
            print("‚ùå BERTScore compute failed:", e)
            sys.exit(1)

        # unpack into dataframe
        df["precision"] = out["precision"]
        df["recall"]    = out["recall"]
        df["f1"]        = out["f1"]

        # macro‚Äêaverage
        model_metrics = {
            "Model": "roberta-large",
            "Precision": sum(df["precision"]) / len(df["precision"]),
            "Recall":    sum(df["recall"])    / len(df["recall"]),
            "F1":        sum(df["f1"])        / len(df["f1"]),
        }

        # write to Excel
        report_path = Path(output_dir) / "Bertscore_output.xlsx"
        with pd.ExcelWriter(report_path, engine="xlsxwriter") as writer:
            df.to_excel(writer, sheet_name="Detailed_metrics", index=False)
            pd.DataFrame([model_metrics]).to_excel(
                writer, sheet_name="Model_metrics", index=False
            )

        print(f"‚úÖ Report saved to {report_path.resolve()}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run BERTScore Metric Calculator"
    )
    parser.add_argument(
        "--output_dir", type=str, required=True,
        help="Directory where Bertscore_output.xlsx will be saved"
    )
    parser.add_argument(
        "files", nargs="+",
        help="One or more input Excel files (.xls/.xlsx)"
    )
    args = parser.parse_args()

    print(f"Output directory: {args.output_dir}")
    print(f"Input files: {args.files}")
    main(args.files, args.output_dir)