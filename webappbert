#!/usr/bin/env python
import os
import sys
import argparse
from pathlib import Path

import pandas as pd
import evaluate  # will load your local bertscore.py

def main():
    parser = argparse.ArgumentParser(
        description="Run BERTScore metrics with your local bertscore implementation"
    )
    parser.add_argument(
        "--output_dir",
        type=Path,
        required=True,
        help="Directory in which to write Bertscore_output.xlsx"
    )
    parser.add_argument(
        "files",
        nargs="+",
        help="One or more input .xls/.xlsx/.csv files containing 'reference' & 'candidate' columns"
    )
    args = parser.parse_args()

    # ─── your exact environment settings ──────────────────────────────────────────
    MODEL_PATH    = os.getenv(
        "BERT",
        "C:/Users/ZKC7HOU/Documents/4. BERT score/roberta-large"
    )
    DEVICE        = "cuda" if os.environ.get("CUDA_VISIBLE_DEVICES") else "cpu"
    BASELINE_PATH = "C:/Users/ZKC7HOU/Documents/4. BERT score/roberta-large/Versions-delete/roberta-large.tsv"
    # ────────────────────────────────────────────────────────────────────────────────

    # Locate **your** local metric script
    wrapper_dir = Path(__file__).parent
    metric_py   = wrapper_dir / "Bertscore.py"
    if not metric_py.exists():
        print(f"ERROR: can't find local metric at {metric_py}", file=sys.stderr)
        sys.exit(1)

    # Load it explicitly by path
    try:
        scorer = evaluate.load(str(metric_py))
    except Exception as e:
        print("ERROR: failed to load bertscore metric:", e, file=sys.stderr)
        sys.exit(1)

    # Read & concatenate all input files
    dfs = []
    for fp in args.files:
        p = Path(fp)
        if not p.exists():
            print(f"ERROR: file not found: {fp}", file=sys.stderr)
            sys.exit(1)
        suf = p.suffix.lower()
        if suf in (".xls", ".xlsx"):
            dfs.append(pd.read_excel(p))
        elif suf == ".csv":
            dfs.append(pd.read_csv(p))
        else:
            print(f"ERROR: unsupported file type: {suf}", file=sys.stderr)
            sys.exit(1)
    df = pd.concat(dfs, ignore_index=True)

    # Validate columns
    for col in ("reference", "candidate"):
        if col not in df.columns:
            print(f"ERROR: missing required column '{col}'", file=sys.stderr)
            sys.exit(1)

    # Compute BERTScore
    print("▶ Computing BERTScore…")
    out = scorer.compute(
        predictions=df["candidate"].astype(str).tolist(),
        references=df["reference"].astype(str).tolist(),
        model_type=MODEL_PATH,
        num_layers=17,
        device=DEVICE,
        rescale_with_baseline=True,
        baseline_path=BASELINE_PATH,
        lang="en"
    )

    # Attach to DataFrame
    df["precision"] = [round(min(max(x,0.0),1.0),6) for x in out["precision"]]
    df["recall"]    = [round(min(max(x,0.0),1.0),6) for x in out["recall"]]
    df["f1"]        = [round(min(max(x,0.0),1.0),6) for x in out["f1"]]

    # Write out Excel where your JSON expects it
    out_dir     = args.output_dir
    out_dir.mkdir(parents=True, exist_ok=True)
    output_fp   = out_dir / "Bertscore_output.xlsx"
    df.to_excel(output_fp, index=False)

    # Single success line for Flask to capture
    print(f"✔️ Report saved to: {output_fp.resolve()}")

if __name__ == "__main__":
    main()