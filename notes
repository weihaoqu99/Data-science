import sys, subprocess
subprocess.check_call([sys.executable, "-m", "pip",
                       "install", "--upgrade", "transformers==4.52.4",
                       "--force-reinstall", "--no-cache-dir"])


import sys, subprocess
subprocess.check_call([sys.executable, "-m", "pip", "install", "--upgrade", "transformers"])
# then immediately restart your kernel (Runtime → Restart Kernel)


Generation-Time Hyperparameters

Parameter
Typical Range
Why It Helps
generation_num_beams
4 – 8
Beam search width. More beams → higher BLEU but slower; too many can produce generic text.
length_penalty
0.6 – 1.2
<1.0 → favors shorter output; >1.0 → favors longer. Calibrate so translations aren’t truncated.
no_repeat_ngram_size
1 – 3
Prevents exact n-gram repeats. Helps avoid stuttering or looping phrases.
early_stopping
True/False
If True, stops beam search when the best beam is finished — can slightly speed up decoding.
repetition_penalty
1.0 – 1.5
Penalizes tokens already generated, making output more varied and less “hallucinatory.”
temperature
0.7 – 1.0
(if you sample) lower → more conservative; higher → more creative but less faithful.
max_new_tokens
64 – 128
Hard cap on generated length. Ensures you don’t get runaway outputs or truncation of valid content.
