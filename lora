# ====== env ======
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "0,1,2,3"

# ====== (optional) accelerate shim for older versions ======
import sys, types
def _safe_clear_device_cache():
    try:
        import torch
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            try: torch.cuda.ipc_collect()
            except Exception: pass
    except Exception: pass
try:
    import importlib
    _mem = importlib.import_module("accelerate.utils.memory")
    if not hasattr(_mem, "clear_device_cache"):
        setattr(_mem, "clear_device_cache", _safe_clear_device_cache)
        print("Patched accelerate.utils.memory.clear_device_cache")
except Exception:
    mem_mod = types.ModuleType("accelerate.utils.memory")
    mem_mod.clear_device_cache = _safe_clear_device_cache
    sys.modules["accelerate.utils.memory"] = mem_mod
    print("Injected accelerate.utils.memory module with clear_device_cache")

# ====== data ======
from datasets import Dataset, Audio
import glob

audio_files = glob.glob("/appdata/cortex/dev1/origAudio/*.mp3")

def retrieve_transcript(input_str: str) -> str:
    tmp = input_str[input_str.find('/')+1:-4]
    tmp = tmp.replace('_', ' ').replace('.', ' ')
    tmp = tmp.replace("shell", "she'll").replace("dont", "don't")
    tmp = tmp.capitalize().replace('i ', 'I ')
    return tmp

transcripts = [retrieve_transcript(s) for s in audio_files]
num_samples = len(audio_files)

raw_datasets = Dataset.from_dict({
    "audio": audio_files[:num_samples],
    "sentence": transcripts[:num_samples]
}).cast_column("audio", Audio(sampling_rate=16_000))
raw_datasets = raw_datasets.train_test_split(test_size=0.15, seed=91)

# ====== processor ======
from transformers import WhisperProcessor
whisper_loc = "/appdata/cortex/dev1/whisper_copy/distil-large-v2"
processor = WhisperProcessor.from_pretrained(whisper_loc, language