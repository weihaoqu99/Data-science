#!/usr/bin/env python
import os
import sys
import argparse
from pathlib import Path

import pandas as pd
import evaluate
import numpy as np
import torch

# ─── Offline HuggingFace setup ─────────────────────────────────────────────
# Point these at your on-disk model and baseline .tsv
MODEL_PATH    = r"C:/Users/ZKC7HOU/Documents/4. BERT score/roberta-large"
BASELINE_PATH = r"C:/Users/ZKC7HOU/Documents/4. BERT score/roberta-large/en/roberta-large.tsv"
DEVICE        = "cuda" if torch.cuda.is_available() else "cpu"
# ────────────────────────────────────────────────────────────────────────────

def main():
    parser = argparse.ArgumentParser(
        description="Compute BERTScore offline via HuggingFace evaluate"
    )
    parser.add_argument(
        "--output_dir",
        type=Path,
        required=True,
        help="Directory to write Bertscore_output.xlsx"
    )
    parser.add_argument(
        "files",
        nargs="+",
        help="One or more .csv/.xls/.xlsx files with 'reference' & 'candidate' columns"
    )
    args = parser.parse_args()

    # ─── Load the custom bertscore metric from local script ─────────────────
    try:
        # the path here is relative to where this script lives
        metric_script = Path(__file__).parent / "bertscore.py"
        scorer = evaluate.load(str(metric_script), module_type="metric")
    except Exception as e:
        print("ERROR: failed to load local bertscore metric:", e, file=sys.stderr)
        sys.exit(1)
    # ─────────────────────────────────────────────────────────────────────────

    # ─── Read & concatenate all inputs ──────────────────────────────────────
    dfs = []
    for fn in args.files:
        p = Path(fn)
        if p.suffix.lower() in (".xls", ".xlsx"):
            dfs.append(pd.read_excel(p))
        elif p.suffix.lower() == ".csv":
            dfs.append(pd.read_csv(p))
        else:
            print(f"ERROR: unsupported file type {p.suffix}", file=sys.stderr)
            sys.exit(1)
    if not dfs:
        print("ERROR: no data loaded", file=sys.stderr)
        sys.exit(1)
    df = pd.concat(dfs, ignore_index=True)
    # ─────────────────────────────────────────────────────────────────────────

    # ─── Verify required columns ────────────────────────────────────────────
    for col in ("reference", "candidate"):
        if col not in df.columns:
            print(f"ERROR: missing required column '{col}'", file=sys.stderr)
            sys.exit(1)
    # ─────────────────────────────────────────────────────────────────────────

    # ─── Compute BERTScore via evaluate.scorer ───────────────────────────────
    out = scorer.compute(
        predictions=df["candidate"].astype(str).tolist(),
        references=df["reference"].astype(str).tolist(),
        model_type=MODEL_PATH,
        num_layers=17,
        device=DEVICE,
        rescale_with_baseline=True,
        baseline_path=BASELINE_PATH,
        lang="en"
    )

    # round & attach
    df["precision"] = [round(x, 6) for x in out["precision"]]
    df["recall"]    = [round(x, 6) for x in out["recall"]]
    df["f1"]        = [round(x, 6) for x in out["f1"]]
    # ─────────────────────────────────────────────────────────────────────────

    # ─── Write result to Excel ───────────────────────────────────────────────
    args.output_dir.mkdir(parents=True, exist_ok=True)
    out_fp = args.output_dir / "Bertscore_output.xlsx"
    df.to_excel(out_fp, index=False)
    print(f"✔️  Report saved to: {out_fp.resolve()}")
    # ─────────────────────────────────────────────────────────────────────────

if __name__ == "__main__":
    main()