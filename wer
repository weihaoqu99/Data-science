import jiwer

def compute_metrics(pred):
    pred_ids = pred.predictions
    label_ids = pred.label_ids

    # replace -100 with pad_token_id
    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id

    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)
    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)

    # compute WER with jiwer
    wer = jiwer.wer(label_str, pred_str) * 100

    return {"wer": wer}



print(vectorized_datasets)
print(vectorized_datasets["train"][0].keys())   # 


should show: dict_keys(['input_features','labels'])




from datasets.features.audio import set_audio_backend
set_audio_backend("librosa")   # put this BEFORE you call .cast_column(...)


pip install librosa audioread
# (ffmpeg is recommended so audioread can decode mp3)

from datasets import Dataset, Audio
from datasets.features.audio import set_audio_backend
set_audio_backend("librosa")

raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}) \
             .cast_column("audio", Audio(sampling_rate=16_000))



# ---- put this at the very top of the notebook ----
import sys, types
sf_stub = types.ModuleType("soundfile")
sf_stub.__spec__ = None
sf_stub.libsndfile_version = "0.0.0"  # forces features that require libsndfile to be disabled
sys.modules["soundfile"] = sf_stub

# deps purely in Python
%pip install -q librosa audioread

# now it's safe to import datasets without crashing
from datasets import Dataset, Audio
import librosa

raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}) \
             .cast_column("audio", Audio(decode=False))
raw_datasets = raw.train_test_split(test_size=0.15, seed=91)

def prepare_dataset(batch):
    path = batch["audio"]["path"]
    array, sr = librosa.load(path, sr=16000, mono=True)
    batch["input_features"] = processor.feature_extractor(array, sampling_rate=16000).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch

vectorized_datasets = raw_datasets.map(
    prepare_dataset,
    remove_columns=raw_datasets.column_names["train"],
    num_proc=8
)



# ---- put this at the very top of the notebook, before any datasets import ----
import sys, types, importlib, importlib.machinery, importlib.util

# create a stub module with a valid spec and the attribute datasets probes
sf_stub = types.ModuleType("soundfile")
sf_stub.__dict__.update({
    "__spec__": importlib.machinery.ModuleSpec("soundfile", loader=None),
    "libsndfile_version": "0.0.0",   # make the probe evaluate safely
})
sys.modules["soundfile"] = sf_stub

# ensure find_spec("soundfile") returns a spec instead of raising
_orig_find_spec = importlib.util.find_spec
def _fake_find_spec(name, package=None):
    if name == "soundfile":
        return importlib.machinery.ModuleSpec("soundfile", loader=None)
    return _orig_find_spec(name, package)
importlib.util.find_spec = _fake_find_spec

# optional: use librosa for decoding later
%pip install -q librosa audioread

from datasets import Dataset, Audio
import librosa

# build dataset WITHOUT decoding; decode with librosa in map()
raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}).cast_column(
    "audio", Audio(decode=False)
)

def prepare_dataset(batch):
    path = batch["audio"]["path"]
    array, sr = librosa.load(path, sr=16000, mono=True)
    batch["input_features"] = processor.feature_extractor(array, sampling_rate=16000).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch



# --- put this in the VERY FIRST cell, before any `datasets` import ---
import sys, types, importlib, importlib.machinery, importlib.util

# create a stub that satisfies datasets' probes
sf_stub = types.ModuleType("soundfile")
sf_stub.__spec__ = importlib.machinery.ModuleSpec("soundfile", loader=None)
sf_stub.__libsndfile_version__ = "0.0.0"   # <-- exact name expected by datasets
sf_stub.libsndfile_version = "0.0.0"       # (some versions check this too)
sys.modules["soundfile"] = sf_stub

# ensure find_spec("soundfile") returns a spec
_orig_find_spec = importlib.util.find_spec
def _fake_find_spec(name, package=None):
    if name == "soundfile":
        return importlib.machinery.ModuleSpec("soundfile", loader=None)
    return _orig_find_spec(name, package)
importlib.util.find_spec = _fake_find_spec

# optional pure-Python decoders
%pip install -q librosa audioread

from datasets import Dataset, Audio
import librosa

# build WITHOUT decoding; decode in map()
raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}) \
             .cast_column("audio", Audio(decode=False))

def prepare_dataset(batch):
    path = batch["audio"]["path"]
    array, _ = librosa.load(path, sr=16000, mono=True)
    batch["input_features"] = processor.feature_extractor(array, sampling_rate=16000).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch


# conda (recommended)
conda install -c conda-forge libsndfile ffmpeg soundfile librosa audioread
# --- STUB SOUNDFILE (no libsndfile needed) ---
import sys, types, importlib, importlib.machinery, importlib.util

# if a previous bad stub exists, remove it
sys.modules.pop("soundfile", None)

# make a minimal stub with the attributes datasets probes
sf_stub = types.ModuleType("soundfile")
sf_stub.__spec__ = importlib.machinery.ModuleSpec("soundfile", loader=None)
sf_stub.__file__ = "<soundfile-stub>"
sf_stub.__package__ = ""
sf_stub.__libsndfile_version__ = "0.0.0"   # <â€” EXACT NAME REQUIRED
sf_stub.libsndfile_version = "0.0.0"       # some versions also check this
sys.modules["soundfile"] = sf_stub

# make importlib.util.find_spec('soundfile') return a spec (not None)
_orig_find_spec = importlib.util.find_spec
def _safe_find_spec(name, package=None):
    if name == "soundfile":
        return sf_stub.__spec__
    return _orig_find_spec(name, package)
importlib.util.find_spec = _safe_find_spec

