





import jiwer

def compute_metrics(pred):
    pred_ids = pred.predictions
    label_ids = pred.label_ids

    # replace -100 with pad_token_id
    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id

    pred_str = processor.tokenizer.batch_decode(pred_ids, skip_special_tokens=True)
    label_str = processor.tokenizer.batch_decode(label_ids, skip_special_tokens=True)

    # compute WER with jiwer
    wer = jiwer.wer(label_str, pred_str) * 100

    return {"wer": wer}



print(vectorized_datasets)
print(vectorized_datasets["train"][0].keys())   # 


should show: dict_keys(['input_features','labels'])




from datasets.features.audio import set_audio_backend
set_audio_backend("librosa")   # put this BEFORE you call .cast_column(...)


pip install librosa audioread
# (ffmpeg is recommended so audioread can decode mp3)

from datasets import Dataset, Audio
from datasets.features.audio import set_audio_backend
set_audio_backend("librosa")

raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}) \
             .cast_column("audio", Audio(sampling_rate=16_000))



# ---- put this at the very top of the notebook ----
import sys, types
sf_stub = types.ModuleType("soundfile")
sf_stub.__spec__ = None
sf_stub.libsndfile_version = "0.0.0"  # forces features that require libsndfile to be disabled
sys.modules["soundfile"] = sf_stub

# deps purely in Python
%pip install -q librosa audioread

# now it's safe to import datasets without crashing
from datasets import Dataset, Audio
import librosa

raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}) \
             .cast_column("audio", Audio(decode=False))
raw_datasets = raw.train_test_split(test_size=0.15, seed=91)

def prepare_dataset(batch):
    path = batch["audio"]["path"]
    array, sr = librosa.load(path, sr=16000, mono=True)
    batch["input_features"] = processor.feature_extractor(array, sampling_rate=16000).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch

vectorized_datasets = raw_datasets.map(
    prepare_dataset,
    remove_columns=raw_datasets.column_names["train"],
    num_proc=8
)



# ---- put this at the very top of the notebook, before any datasets import ----
import sys, types, importlib, importlib.machinery, importlib.util

# create a stub module with a valid spec and the attribute datasets probes
sf_stub = types.ModuleType("soundfile")
sf_stub.__dict__.update({
    "__spec__": importlib.machinery.ModuleSpec("soundfile", loader=None),
    "libsndfile_version": "0.0.0",   # make the probe evaluate safely
})
sys.modules["soundfile"] = sf_stub

# ensure find_spec("soundfile") returns a spec instead of raising
_orig_find_spec = importlib.util.find_spec
def _fake_find_spec(name, package=None):
    if name == "soundfile":
        return importlib.machinery.ModuleSpec("soundfile", loader=None)
    return _orig_find_spec(name, package)
importlib.util.find_spec = _fake_find_spec

# optional: use librosa for decoding later
%pip install -q librosa audioread

from datasets import Dataset, Audio
import librosa

# build dataset WITHOUT decoding; decode with librosa in map()
raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}).cast_column(
    "audio", Audio(decode=False)
)

def prepare_dataset(batch):
    path = batch["audio"]["path"]
    array, sr = librosa.load(path, sr=16000, mono=True)
    batch["input_features"] = processor.feature_extractor(array, sampling_rate=16000).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch



# --- put this in the VERY FIRST cell, before any `datasets` import ---
import sys, types, importlib, importlib.machinery, importlib.util

# create a stub that satisfies datasets' probes
sf_stub = types.ModuleType("soundfile")
sf_stub.__spec__ = importlib.machinery.ModuleSpec("soundfile", loader=None)
sf_stub.__libsndfile_version__ = "0.0.0"   # <-- exact name expected by datasets
sf_stub.libsndfile_version = "0.0.0"       # (some versions check this too)
sys.modules["soundfile"] = sf_stub

# ensure find_spec("soundfile") returns a spec
_orig_find_spec = importlib.util.find_spec
def _fake_find_spec(name, package=None):
    if name == "soundfile":
        return importlib.machinery.ModuleSpec("soundfile", loader=None)
    return _orig_find_spec(name, package)
importlib.util.find_spec = _fake_find_spec

# optional pure-Python decoders
%pip install -q librosa audioread

from datasets import Dataset, Audio
import librosa

# build WITHOUT decoding; decode in map()
raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}) \
             .cast_column("audio", Audio(decode=False))

def prepare_dataset(batch):
    path = batch["audio"]["path"]
    array, _ = librosa.load(path, sr=16000, mono=True)
    batch["input_features"] = processor.feature_extractor(array, sampling_rate=16000).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch


# conda (recommended)
conda install -c conda-forge libsndfile ffmpeg soundfile librosa audioread
# --- STUB SOUNDFILE (no libsndfile needed) ---
import sys, types, importlib, importlib.machinery, importlib.util

# if a previous bad stub exists, remove it
sys.modules.pop("soundfile", None)

# make a minimal stub with the attributes datasets probes
sf_stub = types.ModuleType("soundfile")
sf_stub.__spec__ = importlib.machinery.ModuleSpec("soundfile", loader=None)
sf_stub.__file__ = "<soundfile-stub>"
sf_stub.__package__ = ""
sf_stub.__libsndfile_version__ = "0.0.0"   # <— EXACT NAME REQUIRED
sf_stub.libsndfile_version = "0.0.0"       # some versions also check this
sys.modules["soundfile"] = sf_stub

# make importlib.util.find_spec('soundfile') return a spec (not None)
_orig_find_spec = importlib.util.find_spec
def _safe_find_spec(name, package=None):
    if name == "soundfile":
        return sf_stub.__spec__
    return _orig_find_spec(name, package)
importlib.util.find_spec = _safe_find_spec

# --- SOUNDFILE STUB: must run before importing `datasets` ---
import sys, types, importlib, importlib.machinery, importlib.util

# remove any previously loaded soundfile
sys.modules.pop("soundfile", None)

# create stub with the exact attributes `datasets` expects
_sf = types.ModuleType("soundfile")
_sf.__spec__ = importlib.machinery.ModuleSpec("soundfile", loader=None)
_sf.__file__ = "<soundfile-stub>"
_sf.__package__ = ""
_sf.__libsndfile_version__ = "0.0.0"   # EXACT attribute name required
_sf.libsndfile_version = "0.0.0"       # some versions also check this
sys.modules["soundfile"] = _sf

# keep original find_spec, then patch safely (to avoid recursion)
_orig_find_spec = importlib.util.find_spec
def _safe_find_spec(name, package=None):
    if name == "soundfile":
        return _sf.__spec__
    return _orig_find_spec(name, package)
importlib.util.find_spec = _safe_find_spec

# quick self-check
import importlib as _il
mod = _il.import_module("soundfile")
assert hasattr(mod, "__libsndfile_version__"), "stub missing __libsndfile_version__"





raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}) \
             .cast_column("audio", Audio(decode=False))

raw_datasets = raw.train_test_split(test_size=0.15, seed=91)

def prepare_dataset(batch):
    path = batch["audio"]["path"]
    array, _ = librosa.load(path, sr=16000, mono=True)
    batch["input_features"] = processor.feature_extractor(array, sampling_rate=16000).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch



from datasets import Dataset, Audio
import librosa

# 1) Build WITHOUT decoding (very important)
raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}).cast_column(
    "audio", Audio(decode=False)
)

# 2) Split and force plain Python format so printing doesn’t decode
raw_datasets = raw.train_test_split(test_size=0.15, seed=91)
raw_datasets = raw_datasets.with_format("python")


# Don’t do: [r["sentence"] for r in raw_datasets["test"]]  # triggers decoding
print(raw_datasets["test"]["sentence"][:10])                # SAFE (column access)

# or drop the audio column before looking at rows:
print(raw_datasets["test"].remove_columns("audio")[:3])     # SAFE

def prepare_dataset(batch):
    path = batch["audio"]["path"]                     # path only; not decoded
    array, _ = librosa.load(path, sr=16000, mono=True)
    batch["input_features"] = processor.feature_extractor(
        array, sampling_rate=16000
    ).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch

vectorized_datasets = raw_datasets.map(
    prepare_dataset,
    remove_columns=raw_datasets.column_names["train"],
    num_proc=8
)

print(vectorized_datasets["train"][0].keys())  # should be dict_keys(['input_features','labels'])





import numpy as np, audioread, resampy

def load_audio_ar(path: str, sr: int = 16000) -> tuple[np.ndarray, int]:
    """Decode audio via audioread (FFmpeg/MediaFoundation/CoreAudio),
    convert to mono float32 in [-1,1], and resample to `sr`."""
    with audioread.audio_open(path) as f:
        sr_native = f.samplerate
        ch = f.channels

        # concatenate raw PCM chunks
        pcm = b"".join(b for b in f)

    # audioread gives 16-bit PCM for MP3/WAV → int16 → float32
    y = np.frombuffer(pcm, dtype=np.int16).astype(np.float32) / 32768.0

    # deinterleave → mono
    if ch > 1:
        y = y.reshape(-1, ch).mean(axis=1)

    # resample if needed
    if sr_native != sr:
        y = resampy.resample(y, sr_native, sr)

    return y, sr

def prepare_dataset(batch):
    path = batch["audio"]["path"]                 # path only; not decoded
    array, _ = load_audio_ar(path, sr=16000)      # <-- use audioread loader
    batch["input_features"] = processor.feature_extractor(
        array, sampling_rate=16000
    ).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch

from datasets import Dataset, Audio
raw = Dataset.from_dict({"audio": audio_files, "sentence": transcripts}).cast_column(
    "audio", Audio(decode=False)
)
raw_datasets = raw.train_test_split(test_size=0.15, seed=91).with_format("python")

# Also avoid multiprocessing (workers re-import audio stacks):
vectorized_datasets = raw_datasets.map(
    prepare_dataset,
    remove_columns=raw_datasets.column_names["train"],
    num_proc=1,                      # <- important
    desc="Preparing dataset"
)



import subprocess; subprocess.run(["ffmpeg","-version"])



# --- pick ONE loader ---

# If you have FFmpeg installed (recommended):
import numpy as np, audioread, resampy

def load_audio(path, sr=16000):
    with audioread.audio_open(path) as f:
        sr_native = f.samplerate
        ch = f.channels
        pcm = b"".join(b for b in f)
    y = np.frombuffer(pcm, dtype=np.int16).astype(np.float32) / 32768.0
    if ch > 1:
        y = y.reshape(-1, ch).mean(axis=1)
    if sr_native != sr:
        y = resampy.resample(y, sr_native, sr)
    return y, sr

# If you don't have FFmpeg but files are WAV only, you can use librosa:
# import librosa
# def load_audio(path, sr=16000):
#     y, _ = librosa.load(path, sr=sr, mono=True)
#     return y, sr

def prepare_dataset(batch):
    # dataset was built with Audio(decode=False), so we only have a file path
    path = batch["audio"]["path"]
    array, _ = load_audio(path, sr=16000)

    batch["input_features"] = processor.feature_extractor(
        array, sampling_rate=16000
    ).input_features[0]

    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch

# IMPORTANT: run mapping in a single process so no audio stack gets re-imported
vectorized_datasets = raw_datasets.map(
    prepare_dataset,
    remove_columns=raw_datasets.column_names["train"],
    num_proc=1,                       # <-- not 8
    desc="Preparing dataset",
)

def prepare_dataset(batch):
    a = batch["audio"]
    if isinstance(a, dict) and "array" in a and a["array"] is not None:
        array = a["array"]
        sr = a.get("sampling_rate", 16000)
    else:
        path = a["path"] if isinstance(a, dict) else a
        array, sr = load_audio(path, sr=16000)

    batch["input_features"] = processor.feature_extractor(array, sampling_rate=16000).input_features[0]
    batch["labels"] = processor.tokenizer(batch["sentence"]).input_ids
    return batch